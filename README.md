# CUDA MODE Resource Stream



## Papers, Case Studies
- [A Case Study in CUDA Kernel Fusion: Implementing FlashAttention-2 on NVIDIA Hopper Architecture using the CUTLASS Library](https://arxiv.org/abs/2312.11918)



## Books
- [Programming Massively Parallel Processors: A Hands-on Approach](https://www.amazon.com/Programming-Massively-Parallel-Processors-Hands/dp/0323912311)



## Tri Dao Fan Section
- [Dao-AILab/flash-attention](https://github.com/Dao-AILab/flash-attention)
- [state-spaces/mamba](https://github.com/state-spaces/mamba)

## Practice
- [Sasha Rush's GPU Puzzles](https://github.com/srush/GPU-Puzzles)

## PyTorch Highlights
- [Accelerating Generative AI with PyTorch: Segment Anything, Fast](https://pytorch.org/blog/accelerating-generative-ai/)
- [Accelerating Generative AI with PyTorch II: GPT, Fast](https://pytorch.org/blog/accelerating-generative-ai-2/)
- [PyTorch Compiler Troubleshooting](https://github.com/pytorch/pytorch/blob/main/docs/source/torch.compiler_troubleshooting.rst)
